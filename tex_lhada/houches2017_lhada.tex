\documentclass[11pt]{cernrep}
\usepackage{graphicx,epsfig}
\usepackage{amsmath}
\usepackage[T1]{fontenc}
\usepackage{fancyvrb}
\bibliographystyle{lesHouches}
\begin{document}


\author{Philippe~Gras$^{1}$, Harrison~B.~Prosper$^{2}$, Sezen~Sekmen$^{3}$}

\institute{
  $^{1}$ IRFU, CEA, Universit\'e Paris-Saclay, Gif-sur-Yvette, France\\
  $^{2}$ Department of Physics, Florida State University, Tallahassee, Florida 32306, USA\\
  $^{2}$ Kyungpook National University, Daegu, South Korea
}


\title{Analysis description for LHC result reinterpretations}\label{LHADA}

\maketitle

\abstract{{\sc Lhada} is a language to describe LHC analysis which has a wide range of applications. In this work, this language is investigated for its usage in the context of LHC result reinterpretation. It would be employed to describe in an unambiguous and concise manner a data analysis including all the details needed for a reinterpretation of the result in the context of a physics theory not considered in the original analysis. A specialisation of the language dedicated to reinterpretation is introduced. The specialisation defines extra syntax rules and constitutes a subset of the language. Three different analyses used as benchmarks are described with this language. Automatic generation of code reproducing the analysis on Monte-Carlo samples for the purpose of result reinterpretation is investigated. We demonstrate that programs that generates code to be used in a result reinterpretation tool can be easily developed and a prototype is presented. In addition, the generated code can be used to validate the accuracy of the analysis description.}

\section{Introduction}

The need for a standard to describe analyses of LHC data in an unambiguous way together with the definition of its requirements has been studied at the 2015 session of Les Houches PhysTeV workshop~\cite{Brooijmans:2016vro}. The study includes a proposal for this standard, called Les Houches analysis description accord ({\sc Lhada}). In this work, we investigate this proposal in the context of analysis reinterpretation. Three questions are addressed: the coverage of the language, that is its ability to implement a large spectrum of analyses, the completeness of the analysis description, and the capacity to validate this description. The first question is addressed by implementing the description of example analyses with different levels of complexity. The second and third questions were addressed by developing two machine interpreters. The interpreters generate c$++$ code that reproduces the analysis on an input samples. There is an alternative approach, taken by the {\tt CutLang}~\cite{Sekmen:2018ehb} interpreter, which does a direct runtime interpretation of its internal text based analysis description language.  One of the two interpreters detailed in the following study produces a module, so-called ``Rivet analysis'', for the {\sc Rivet}~\cite{Buckley:2010ar} framework, while the second produces a standalone code based on the ROOT~\cite{Brun:1997pa} framework. The {\sc Rivet} based code is meant to be used for result reinterpretation. It can also be used to validate an analysis description by reproducing reference numbers provided by the analysis authors. In particular the cut flow, that is the acceptances of the subsequent selections (the ``cuts'') of the analysis, is well suited for such validation~\cite{Kraml:2012sg}. The completeness of the description is validated at the same time. The second interpreter, called {\sc Lhada2TNM} is aimed towards running a {\sc Lhada} analysis on any given type of input ROOT ntuple, and targets a more generic use, including design and implementation of analyses with the experimental data.

\section{Describing analyses in {\sc Lhada}}

In order to test the suitability of the {\sc Lhada} language to describe LHC analyses, three different new physics searches have been considered. The first analysis is the {\em Search for new physics in the all-hadronic final state with the MT2 variable} from Ref.~\cite{CMS:2016xva}. The two other analyses are the {\em Search for squarks and gluinos in final states with jets and missing transverse momentum at $\sqrt{s} = 13\,$TeV  with the ATLAS detector}~\cite{Aaboud:2016zdn} and {\em Search for dark matter at $\sqrt{s}=13\,$TeV in final states containing an energetic photon and large missing transverse momentum with the ATLAS detector}~\cite{Aaboud:2017dor}, which are used for the comparison of the reinterpretation tools performed in Contribution~\verb|\ref{sec:recast}|.

We have described the three analyses with the {\sc Lhada} language and the descriptions can be found in the analysis descriptions database~\cite{bib:lhada_git} respectively under {\tt lhada/analyses/CMS-PAS-SUS-16-015}, {\tt lhada/analyses /ATLASSUSY1605.03814}, and {\tt lhada/analyses/ATLASEXOT1704. 0384}. No particular difficulty has been encountered. The {\sc Lhada17} language subset has been used and a cut flow table has been included [editor's note: to be added] in the description to allow the validation of the descriptions using code generated with the interpreter.


\section{Generating a Rivet analysis from {\sc Lhada}}

{\sc Lhada} is a multipurpose and flexible language. In the case of {\sc Lhada2rivet}, the interpreter that generates a Rivet analysis, we have chosen to limit ourselves to the analysis reinterpretation use case and to specify accurately the analysis description language understood by the program. For this purpose, we have derived a subset of the {\sc Lhada} language, called {\sc Lhada17}. In this section, we will first draw the specifications of this sublanguage. We will then present the automatic generation of Rivet analyses.

\subsection{Describing the description language}\label{sec:desc}

%Machine interpretation of the analysis descriptions requires a precise specification of the language. While the level of specification given in Ref.~\cite{Brooijmans:2016vro} is well suited for human interpretation, implementing a parser that support all its flexible is a difficult task. Unnecessary software complexity is required to handle all possible ways to describe the analyses and it is difficult to anticipate all possible cases allowed by the language. In this section we refine these specifications for the purpose of machine interpretation in the context of result reinterpretation. The resulting specifications, we will call {\sc Lhada}17, can be seen as a subset of the {\sc Lhada} language.

The Extended Backus-Naur Form~\cite{bib:ebnf,bib:ebnf-wiki} (EBNF) notation has been used to specify the syntax and grammar of {\sc Lhada}17. The syntax is given in Appendix~\ref{app:ebnf}. The following rules which have not been included in the EBNF syntax to simplify the notation apply:
\begin{itemize}
\item A hash sign (\#) can be used to include comments in the {\sc Lhada} files: all characters of a line starting from a hash sign are comments and ignored for the interpretation based on the EBNF description.
\item If the last non-space character of a line is a backslash ($\backslash$), then the line is merged with the following line before being interpreted according to the EBNF description.
\item An entity ({\tt function}, {\tt object}  or {\tt cut}) should be declared before being used. For instance if a function is used in a ``cut'' definition, the corresponding {\tt function} block should appear before the {\tt cut} line. This rule is meant to simplify the parsing and also to avoid circular definitions. 
\end{itemize}

A specificity of {\sc Lhada} is the usage of programming languages to describe algorithms, via the {\sc Lhada} {\tt functions} while the main structure of the analysis is described with the dedicated language. A reference implementation of the algorithm is provided in a ``commonly used'' programming language. The implementation is given in a code source file, which can group implementations of different {\sc Lhada} {\tt functions} and can be shipped along with the {\sc Lhada} description file or provided as an http link.  In order to ease machine interpretation {\sc Lhada}17 includes the following restrictions for the reference {\tt function} implementations.

\begin{itemize}
\item the implementation is written in c$++$11~\cite{bib:c++11};
\item the implementation must depend only on the code provided in the file and libraries from the restricted set defined below; the file should be compilable with c$++$11 compliant compilers.
\item the allowed types for the function parameters are: {\tt int}, {\tt float}, {\tt double}, {\tt std::string}, {\tt LHADAParticle}, {\tt LHADAJet}, {\tt FourMomentum} and {\tt std::std::vector} of the last three types. Parameters are passed by copy (no modifier) or by constant reference (with {\tt const \&} modifier, like {\tt const LHADAParticle\&}); this rules exclude the use of a templated function; function templates are allowed for auxiliary functions; 
\item {\tt \#include} statements can be used to include header files from the allowed libraries;
\item the file, where the functions is defined should be compilable with c$++$11 compliant compilers;
\item self-contained function are encouraged but not mandatory; by self contained we mean that the file is compilable with c$++$11 compliant compilers after having removed all code except the function and the {\tt \#include} that precedes it;
\item the function can use the random object to draw pseudo-random numbers, whose scope is global to all functions and which provides the methods described in Table~\ref{tab:rand}; 
\end{itemize}

The {\tt LHADAParticle} and {\tt FourMomentum} types are two classes storing the properties listed in Tables~\ref{tab:part} and \ref{tab:mom}. The {\tt LHADAJet} type is identical to {\tt LHADAParticle}, but without the {\tt pdgid} property; it is introduced to distinguish jets from particles. In the {\tt select} and {\tt reject} statements, the property is referred to with its name, while in the c++ code, a method sharing the same name is used, e.g. {\tt name$()$} for the property {\tt name}. The complete class definition can be found in the {\sc Lhada} github repository under {\tt code\_lib/include}.

The restricted set of libraries includes the libraries that comes with the c$++$ standard ({\tt std} libraries) and a common library provided in the {\sc Lhada} github repository in the directory {\tt code\_lib}.  The set of libraries can evolve without requiring a revision of the {\sc Lhada17} language standard and will be defined by a list stored in the {\sc Lhada} repository.

\begin{table}
  \center
  \caption{Definition of the FourMomentum type: list of properties.\label{tab:mom}}
  \begin{tabular}{l|l}
    {\sc Lhada} & Description \\
    \hline
    mass 	& Mass\\
    e 	        & Energy\\
    px 	        & momentum x-component\\
    py 	        & momentum y-component\\
    pz 	        & momentum z-component\\
    pt 	        & absolute transverse momentum\\
    eta         & pseudorapidity\\
    rapidity    & rapidity\\
  \end{tabular}
\end{table}

\begin{table}
  \center
  \caption{Definition of the LHADAParticle type: list of properties coming in addition to the ones of the FourMomentum type.\label{tab:part}}
  \begin{tabular}{l|l}
    Property    & Description \\
    \hline
    pdgid       & PDG particle id\\
    charge      & charge\\
    x           & particle production vertex x-coordinate\\
    y           & particle production vertex y-coordinate\\
    z           & particle production vertex z-coordinate  \\
  \end{tabular}
\end{table}

 
\begin{table}
  \caption{Definition of the random object interface: list of provided methods. \label{tab:rand}}
  \begin{tabular}{l|p{20em}}
    c$++$ method & Description \\
    \hline
    uniform(double x)  & Returns a pseudorandom number following a uniform distribution over the $[0, \text{x}]$ interval.\\
    gauss(double mean, double sigma)    & Returns a pseudorandom number following a Gaussian distribution.\\
    poisson(int mean) & Returns a pseudorandom number following a Poisson distribution.\\
    breitWigner(double mean, double gamma) & Returns a pseudorandom number following a Breit-Wigner distribution. \\
    exp(double tau) & Return a pseudorandom number following the $\exp(-t/\text{tau})$ distribution. \\
    landau(double mean, double sigma) & Returns a pseudorandom number following a Landau distribution. \\
    binomial(int ntot, double prob) & Returns a pseudorandom number in the $[0, \text{ntot}]$ interval following a Binomial distribution.
  \end{tabular}
\end{table}

%%\#include ``lhada17v1.h''?

The {\sc Lhada} language does not explicitly specify how the arguments listed in a {\tt function} block are matched to the arguments of the reference implementation of the function. To prevent confusion, {\sc Lhada17} requires that the arguments appear in the {\tt function} block in the order of the c$++$ function argument list of its reference implementation and with the same name. If the names differ, the arguments should be matched according to their order, though in such case the file can simply be considered as invalid.

An {\tt object} block defines an entity, typically a collection of particles, starting from the input defined by the {\tt take} statement that is transformed by a sequence of {\tt apply}, {\tt select}, and {\tt reject}  statements. The {\tt apply} statement specifies a function that transforms the entity. In {\sc Lhada17}, the function must take as first argument the entity to transform. This argument is specified in the function definition, but not on the {\tt apply} statement, where it is implicit. Collections are filtered with {\tt select} and {\tt reject} statements. A condition to respectively keep or reject a collection element is provided in the form of a boolean expression. In addition to arithmetic and boolean operations, the expression can contain calls to functions. In the examples given in Ref.~\cite{Brooijmans:2016vro}, the functions take the collection element as an implicit argument, but this might not always be the case. In {\sc Lhada17} the following rule applies: if the number of passed arguments is less by one with respect to the expected one, then the collection element to filter is assumed to be implicitly passed as first argument. A mismatch between the expected argument type and the collection element type is considered as ill-formed. While the {\tt apply} statement is valid for an entity which is a single object (e.g. missing transverse momentum), the {\tt select} and {\tt reject} statements are restricted to collections. Blocks without a {\tt take} statement are also allowed. In this case there is no implicit argument in the {\tt apply} statement. It is strongly discourage to use this form when the one with a {\tt take} statement can be used.

The event selection is defined with {\tt cut} blocks. In order to simplify the description of the selection flow, the reference in a {\tt cut} block to another {\tt cut} block, introduced in {\tt Lhada} to allow branching, is allowed in the first statement of the block only.

Three extensions to {\sc Lhada} are introduced in {\sc Lhada17}. The first is the backslash line continuation marker described above. The second extension concerns the {\tt take external} statement of the {\tt object} block. In {\sc Lhada17} is it followed by a label identifying the object. A record of possible objects with their definition and properties (e.g. reconstruction efficiency and resolution in case of reconstructed particles) is kept in the {\tt Lhada} repository. The repository is updated when new objects are needed. Finally, we have introduced two aliases for the keyword {\tt object}: {\tt variable} and {\tt collection}. The {\tt object} block can represent several types of entities. Providing the possibility to use a name reflecting the type of entities, {\tt collection} when dealing with a collection of physics object, {\tt variable} when dealing with a single observable, like an event shape variable, should help in writing more intelligible analysis descriptions. The choice of the name is left to the discretion of the analysis description author.

\subsection{Automatised generation of Rivet analysis code}

The {\sc Lhada} language will play a role for LHC result reinterpretations only if it is interfaced to commonly used reinterpretation frameworks. The interface can be done in two different ways. The first approach is to interpret the analysis description at run time. The second one, which is adopted here, is to generate code from the description.

An application, called {\sc Lhada2Rivet}, that produces a Rivet analysis from its description in {\sc Lhada17} is being developed. The analysis produces a cut flow table. Special care has been taken to produce code in the {\sc Rivet} style using facilities provided by the framework, like the projections or the {\tt CutFlow} class.

The detector response effect can be included in two different ways. The interpreter supports a list of reconstructed objects, defined in the {\sc Lhada} repository, using the {\sc Rivet} built-in feature. The {\sc Lhada} description will take reconstructed objects as {\tt external}. Alternatively, the detector effects (efficiency and resolution) can be defined in the {\sc Lhada} description: it then takes generator-level object (typically {\sc HepMC}~\cite{Dobbs:2001ck} particles) as {\tt external} and the detector effect is included using {\tt apply} statements and c$++$ functions. The random object was introduced in {\sc Lhada17} for this purpose and the common library includes a help function that can be called to apply efficiency and resolution effects.

The code produced by the {\sc Lhada2Rivet} interpreter for the first analysis considered in the previous section can be found in appendix~\ref{app:code}. The code was produced with an early version of the interpreter that did not include the detector effect simulation. The code is shown for illustration only and is not fully valid. Each {\sc Lhada} cut block is mapped to a c$++$ method. {\sc Rivet} built-in tools, as Projections and Cutflow are used, leading to a clean code that is well integrated in the framework. The calculation of the event count passing each cut using the Cutflow object is not correct and a proper support of cut flow is under development.  The {\sc Rivet} interface to the fastjet~\cite{Cacciari:2011ma} library is used to cluster the jets.

With this prototype we have investigated the different aspects that a result reinterpretation code generator based on a {\sc Lhada} analysis description should cover. We can conclude from this exercise that the development of such a generator that takes as input a description compliant with the {\sc Lhada17} specifications is possible with a reasonable effort. The code produced by such a generator can be used to validate the analysis description using analysis cut flow, which needs to be provided by the analysis authors.  


\section{The {\sc Lhada2TNM} interpreter}
%
%{\em placeholder for Harrison's contribution.}

Two key design features of {\sc Lhada} are human readability and analysis framework independence. As noted above, framework independence can be tested by attempting to implement tools that automatically translate analyses described using {\sc Lhada} into analyses that can be executed in different analysis frameworks. Human readability demands that  the number of rules and syntactical elements be kept as low as possible. But, since we also demand that {\sc Lhada} be sufficiently expressive to capture the details of LHC analyses, it pays to follow Einstein's advice: ``Everything should be made as simple as possible, but not simpler".    In the prototype of the  {\sc Lhada2TNM} translator, we have tried to place the burden where it properly belongs, namely, on the translator. For example, it is expected that physicists will write {\sc Lhada} files so that blocks appear in a natural order. However, the {\sc Lhada2TNM} translator does not rely on the order of blocks within a {\sc Lhada} file. The appropriate ordering of blocks is handled by the translator. Given a {\tt cut} block called {\tt signal}, which makes use of another called {\tt preselection}, {\sc Lhada2TNM} places  the code for {\tt preselection} before the code for {\tt signal} in the resulting C++ file.

Another example of placing the burden on the translator rather than on the author of a {\sc Lhada} file, concerns statements that span multiple lines. Many computer languages have syntactical elements to identify such statements. However, since {\sc Lhada} is a keyword-value language, continuation marks are not needed because it is possible to identify when the value associated with a statement ends.

The {\sc Lhada2TNM} translator is a {\tt Python} program that translates a {\sc Lhada} file to a C++ program that can be executed within the {\sc TNM} $n$-tuple analysis framework. The translator extracts all the blocks from a {\sc Lhada} file and places them within a data structure that groups the blocks according to type. The {\tt object} and {\tt cut} blocks are ordered according to their dependencies on other object or cut blocks. It is assumed that a standard, extensible, type is available to model all analysis objects and that an adapter exists to translate input types, e.g., {\sc Delphes}, {\sc ATLAS}, {\sc CMS}, etc., types  to the standard type. In order to determine where a statement ends, {\sc Lhada2TNM} looks ahead to the next record in the {\sc Lhada} file during translation.

In the current version, instances of the standard, extensible, type as well as functions are placed in the global namespace of the C++ program so that the object and cut code blocks
that need them can access them without the need to pass objects between code blocks. The name of a function defined in {\sc Lhada} is assumed  to be identical with that of a function, which, ultimately, will be accessed from an online code repository. However, this assumption can be relaxed if warranted in a later iteration of {\sc Lhada}; for example, the appropriate function can be specified by its {\sc DOI}.  While the technical details of the automatic access of
codes from an online repository need to be worked out, we see no insurmountable hurdles.


\section{Conclusion}

The sustainability of the {\sc Lhada} language to be used in the context of analysis reinterpretation has been studied. Three questions have been addressed: the analysis range the language can cover, the completeness of the analysis description, and the capacity to validate the analysis description. The analysis coverage question has been tackled by taking three different LHC searches and implementing their description. The language turns out to be very flexible and no difficulty has been encountered in this exercise giving confidence that the proposed language covers the need. Nevertheless, it will be wise to extend the exercise with a larger number of and more sophisticated analyses. The two other questions have been addressed by developing the prototypes of two applications that interpret analysis descriptions written in {\sc Lhada}. The development of an application generating reinterpretation code out of a {\sc Lhada} analysis description can easily be done provided that the syntax used by the description is well-defined and not too flexible. A specialisation, {\sc Lhada17}, of the {\sc Lhada} language that fulfils this requirement has been set up. The restrictions introduced by {\sc Lhada17} have not been a limitation for the description of the analysis considered in the coverage test. 

\section*{Acknowledgements}

Since the first discussions in Les Houches 2015, many people contributed to developing the {\sc Lhada} concept.  
We would especially like to thank Daniel Dercks, Nishita Desai, Sabine Kraml, Suchita Kulkarni, Gokhan Unel, Federico Ambrogi, Wolfgang Waltenberger, Lukas Heinrich, Roberto Leonardi, Luca Perrozzi, Jim Pivarski, Kati Lassila-Perini, Tibor Simko and the CERN Analysis Preservation Support Group for their valuable input.  We also would like to thank the organizers of Les Houches PhysTeV 2017 workshop for a stimulating and fruitful workshop.

\bibliography{houches2017_lhada.bib}

\section*{Appendices}

\appendix

\section{{\sc Lhada17} language syntax}\label{app:ebnf}

\fvset{fontsize=\footnotesize}
\VerbatimInput{lhada.ebnf}

\section{Example of code produced by the {\sc Ladha2rivet} interpreter}\label{app:code}

\VerbatimInput{CMS_PAS_SUS_16_015.cc}

\end{document} 

